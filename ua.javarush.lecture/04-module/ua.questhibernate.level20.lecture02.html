Big Data: MapReduce
<p>----------------------------------------</p>
Історія виникнення терміну BigData.
Принципи роботи із великими даними.
MapReduce.
Приклади завдань, що ефективно вирішуються за допомогою MapReduce.
<p>----------------------------------------</p>
<h2>3.1 Історія виникнення терміну BigData </h2>

<p>Термін Big Data з'явився порівняно недавно. Google Trends <a href="https://www.google.com/trends/explore" target="_blank">показує</a> початок активного зростання вживання словосполучення починаючи з 2011 року:

<img data-max-width="512" data-id="ef092ce5-6fc8-454f-abb3-dc34b5e97468" src="https://cdn.javarush.com/images/article/ef092ce5-6fc8-454f-abb3 -dc34b5e97468/original.png" alt="">
 
<p>При цьому вже зараз термін не використовує лише лінивий. Особливо часто у справі термін використовують маркетологи. То що таке Big Data насправді? Якщо я вирішив системно викласти і висвітлити питання - необхідно визначитися з поняттям. </p>

<p>У своїй практиці я зустрічався з різними визначеннями:</p>

<ul>
<li>Big Data – це коли даних більше ніж 100Гб (500Гб, 1ТБ, кому що подобається). </li>
<li>Big Data – це дані, які неможливо обробляти в Excel. </li>
<li>Big Data – це дані, які неможливо обробити на одному комп'ютері. </li>
</ul>

<p>І навіть такі: </p>

<ul>
<li>Вig Data – це взагалі будь-які дані. </li>
<li>Big Data не існує, її вигадали маркетологи. </li>
</ul>

<p>Я буду дотримуватися визначення з wikipedia: </p>

<p><strong>Великі дані (англ. big data)</strong> — серія підходів, інструментів і методів обробки структурованих і неструктурованих даних величезних обсягів і значного різноманіття для отримання результатів, що сприймаються людиною, ефективних в умовах безперервного приросту, розподілу по численним вузлам обчислювальної мережі, що сформувалися наприкінці 2000-х років, альтернативних традиційним системам управління базами даних та рішенням класу Business Intelligence. </p>

<p>Таким чином під <strong>Big Data</strong> я розумітиму не якийсь конкретний обсяг даних і навіть не самі дані, а методи їх обробки, які дозволяють розподілено обробляти інформацію. Ці методи можна застосувати як до величезних масивів даних (таких як зміст усіх сторінок в інтернеті), так і до маленьких (таких як вміст цієї лекції).</p>
 
<p>Наведу кілька прикладів того, що може бути джерелом даних, для яких потрібні методи роботи з великими даними:</p>

<ul>
<li>Логи поведінки користувачів в Інтернеті</li>
<li>GPS-сигнали від автомобілів для транспортної компанії</li>
<li>Дані, що знімаються з датчиків у великому адронному колайдері</li>
<li>Оцифровані книги в Російській Державній Бібліотеці</li>
<li>Інформація про транзакції всіх клієнтів банку </li>
<li>Інформація про всі покупки у великій рітейлі мережі і т.д. </li>
</ul>

<p>Кількість джерел даних стрімко зростає, а значить, технології їх обробки стають все більш затребуваними.</p>
 
<h2>3.2 Принципи роботи з великими даними</h2>

<p>Виходячи з визначення Big Data, можна сформулювати основні принципи роботи з такими даними: </p>

<p><strong>1. Горизонтальна масштабованість.</strong> Оскільки даних може бути скільки завгодно – будь-яка система, яка передбачає обробку великих даних, має бути розширюваною. У 2 рази збільшився обсяг даних – у 2 рази збільшили кількість заліза в кластері і все продовжило працювати. </p>

<p><strong>2. Відмовостійкість.</strong> Принцип горизонтальної масштабованості передбачає, що машин у кластері може бути багато. Наприклад, Hadoop-кластер Yahoo має більше 42000 машин (за цим посиланням можна переглянути розміри кластера в різних організаціях). Це означає, що частина цих машин гарантовано виходитиме з ладу. Методи роботи з великими даними повинні враховувати можливість таких збоїв та переживати їх без жодних значних наслідків. </p>

<p><strong>3. Локальність даних.</strong> У великих розподілених системах дані розподілені за великою кількістю машин. Якщо дані фізично знаходяться на одному сервері, а обробляються на іншому – витрати на передачу даних можуть перевищити витрати на обробку. Тому одним із найважливіших принципів проектування BigData-рішень є принцип локальності даних - по можливості обробляємо дані на тій же машині, на якій їх зберігаємо. </p>

<p>Усі сучасні засоби роботи з великими даними так чи інакше дотримуються цих трьох принципів. Для того, щоб їх дотримуватися – необхідно вигадувати якісь методи, способи та парадигми розробки засобів розробки даних. Один із класичних методів я розберу в сьогоднішній лекції. </p>
 
<h2>3.3 MapReduce</h2>

<p><strong>MapReduce</strong> – це модель розподіленої обробки даних, запропонована Google для обробки великих обсягів даних на комп'ютерних кластерах. MapReduce непогано ілюструється наступним малюнком: </p>

<img data-max-width="512" data-id="982b3d98-934f-439d-8f04-5f0994ed46c9" src="https://cdn.javarush.com/images/article/982b3d98-934f-439 -5f0994ed46c9/original.png" alt="">
 
<p>MapReduce передбачає, що дані організовані як деяких записів. Обробка даних відбувається на 3 стадії: </p>

<p><strong>1. Стадія Map</strong>. На цій стадії дані передробляються за допомогою функції map(), яку визначає користувач. Робота цієї стадії полягає у передобробці та фільтрації даних. Робота дуже схожа на операцію map у функціональних мовах програмування – функція користувача застосовується до кожного вхідного запису. </p>

<p><strong>Функція map() застосована до одного вхідного запису і видає безліч пар ключ-значення.</strong> Безліч – тобто може видати лише один запис, може не видати нічого, а може видати кілька пар ключ -значення. Що буде в ключі і в значенні - вирішувати користувачеві, але ключ - дуже важлива річ, оскільки дані з одним ключем у майбутньому потраплять в один екземпляр функції reduce. </p>

<p><strong>2. Стадія Shuffle.</strong> Проходить непомітно для користувача. У цій стадії виведення функції map "розбирається по кошиках" - кожен кошик відповідає одному ключу виведення стадії map. Надалі ці кошики послужать входом до reduce. </p>

<p><strong>3. Стадія Reduce.</strong> Кожен «кошик» зі значеннями, сформований на стадії shuffle, потрапляє на вхід функції reduce(). </p>

<p><strong>Функція reduce задається користувачем та обчислює фінальний результат для окремого «кошика»</strong>. Безліч усіх значень, повернутих функцією reduce(), є фінальним результатом MapReduce-завдання. </p>

<p>Кілька додаткових фактів про MapReduce: </p>

<ol>
<li>Всі запуски функції <strong>map</strong> працюють незалежно і можуть працювати паралельно, у тому числі на різних кластерних машинах. </li>
<li>Всі запуски функції <strong>reduce</strong> працюють незалежно і можуть працювати паралельно, у тому числі на різних кластерних машинах. </li>
<li>Shuffle в собі представляє паралельне сортування, тому також може працювати на різних машинах кластера. <strong>Пункти 1-3 дозволяють виконати принцип горизонтального масштабування</strong>. </li>
<li>Функція map, як правило, застосовується на тій же машині, на якій зберігаються дані - це дозволяє знизити передачу даних через мережу (принцип локальності даних). </li>
<li>MapReduce – це завжди повне сканування даних, жодних індексів немає. Це означає, що MapReduce погано застосовується, коли відповідь потрібна дуже швидко. </li>
</ol>

<h2>3.4 Приклади завдань, які ефективно вирішуються за допомогою MapReduce </h2>

<h4>Word Count </h4>

<p>Почнемо з класичного завдання – Word Count. Завдання формулюється так: є великий корпус документів. Завдання – для кожного слова, хоча б одного разу зустрічається в корпусі, порахувати сумарну кількість разів, яку вона зустріла в корпусі. </p>

<h4>Рішення: </h4>

<p>Якщо маємо великий корпус документів – нехай один документ буде одним вхідним записом для MapRreduce–завдання. У MapReduce ми можемо тільки задавати функції користувача, що ми і зробимо (використовуватимемо python-like псевдокод): </p>

<table>
<tbody>
<tr>
<td><pre><code>def map(doc):
for word in doc:
yield word, 1 </code></pre></td>

<td><pre><code>def reduce(word, values):
yield word, sum(values) </code></pre></td>
 </tr>
</tbody>
</table>

<p>Функція <strong>map</strong> перетворює вхідний документ на набір пар (слово, 1), <strong>shuffle</strong> прозоро для нас перетворює це на пари (слово, [1,1,1,1 ,1,1]), <strong>reduce</strong> підсумовує ці одиниці, повертаючи фінальну відповідь для слова. </p>

<h4>Обробка логів рекламної системи</h4>

<p>Другий приклад взятий із реальної практики Data-Centric Alliance. </p>

<p><strong>Завдання:</strong> є csv-лог рекламної системи виду: </p>

<pre><code>&lt;user_id>,&lt;country>,&lt;city>,&lt;campaign_id>,&lt;creative_id>,&lt;payment>&lt;/p>
 
11111,RU,Moscow,2,4,0.3
22222,RU,Voronezh,2,3,0.2
13413,UA,Kyiv,4,11,0.7
… </code></pre>
 
<p>Необхідно розрахувати середню вартість показу реклами містами Росії. </p>

<h4>Рішення: </h4>

<table>
<tbody>
<tr>
<td><pre><code>def map(record):
user_id, country, city, campaign_id, creative_id, payment = record.split(",")
payment=float(payment)
if country == "RU":
yield city, payment </code></pre></td>
</tr>
<tr>
<td><pre><code>def reduce(city, payments):
yield city, sum(payments)/len(payments)
</code></pre></td>
</tr>
</tbody>
</table>

<p>Функція <strong>map</strong> перевіряє, чи потрібний нам цей запис – і якщо потрібний, залишає лише потрібну інформацію (місто та розмір платежу). Функція <strong>reduce</strong> обчислює фінальну відповідь по місту, маючи список усіх платежів у цьому місті.</p>