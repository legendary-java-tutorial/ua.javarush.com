BigData: HBase
<p>----------------------------------------</p>
Хто і навіщо вигадав HBase.
Модель даних.
Операції, що підтримуються.
Архітектура.
Методи роботи з HBase.
Деякі особливості роботи з HBase.
Альтернативи
<p>----------------------------------------</p>
<h2> 6.1 Хто і навіщо вигадав HBase</h2>
<p>У цій лекції ми поговоримо про такий чудовий інструмент як Hbase, який останнім часом завоював велику популярність: наприклад, Facebook використовує його як основу своєї системи обміну повідомлень, а це вже говорить багато про що. </p>
<p>У лекції розкажемо про концепцію Big Table та її вільну реалізацію, особливості роботи та відмінність як від класичних реляційних баз даних (таких як MySQL та Oracle), так і key-value сховищ, таких як Redis, Aerospike і memcached. Як завжди, почнемо з історії питання. Як і багато інших проєктів з області BigData, Hbase зародилася з концепції, розробленої в Google. Принципи, що лежать в основі Hbase, були описані в статті <a href="https://research.google.com/archive/bigtable-osdi06.pdf" target="_blank">Bigtable: A Distributed Storage System for Structured Data</a>. </p>
<p>Як ми вже розглядали в минулих лекціях, звичайні файли досить непогано підходять для пакетної обробки даних з використанням парадигми MapReduce. З іншого боку, інформацію, що зберігається у файлах, досить незручно оновлювати; файли також не мають можливості довільного доступу. Для швидкої та зручної роботи з довільним доступом є клас nosql-систем типу key-value storage, таких як Aerospike, Redis, Couchbase, Memcached. Однак зазвичай у цих системах дуже незручна пакетна обробка даних. Hbase є спробою об'єднання зручності пакетної обробки і зручності оновлення і довільного доступу. </p>
<img data-max-width="512" data-id="03325dc1-1ff2-4679-bbae-54fe916d9429" src="https://cdn.javarush.com/images/article/03325dc1-1ff2-4679-bbae-54fe916d9429/original.png" alt="">
<h2>2. Модель даних </h2>
<p>HBase — це розподілена, колонково-орієнтована, мультиверсійна база типу «ключ-значення». </p>
<ul>
    <li>Дані організовані в таблиці, проіндексовані первинним ключем, який у Hbase називається RowKey.</li>
    <li>Для кожного RowKey ключа може зберігатися необмежений набір атрибутів (або колонок).</li>
    <li>Колонки організовані в групи колонок, які називають Column Family. Як правило, в одну Column Family об'єднують колонки, для яких однакові патерн використання та зберігання. </li>
    <li>Для кожного атрибута може зберігатися кілька різних версій. Різні версії мають різний timestamp.</li>
</ul>
<p>Записи фізично зберігаються у відсортованому за RowKey порядку. Водночас дані, що відповідають різним Column Family, зберігаються окремо, що дозволяє при необхідності читати дані тільки з потрібного сімейства колонок. </p>
<p>Під час видалення певного атрибуту фізично він відразу не видаляється, а лише маркується спеціальним прапорцем tombstone. Фізичне видалення даних відбудеться пізніше при виконанні операції Major Compaction. </p>
<p>Атрибути, що належать одній групі колонок і відповідають одному ключу, фізично зберігаються як відсортований список. Будь-який атрибут може бути відсутнім або бути присутнім для кожного ключа, при цьому якщо атрибут відсутній, це не викликає накладних витрат на зберігання порожніх значень. </p>
<p>Список та назви груп колонок фіксований і має чітку схему. На рівні групи колонок встановлюються такі параметри як time to live (TTL) і максимальна кількість версій, що зберігаються. Якщо різниця між timestamp для певної версії і поточним часом більше TTL — запис позначається для видалення. Якщо кількість версій для певного атрибуту перевищила максимальну кількість версій, запис також позначається для видалення. </p>
<img data-max-width="512" data-id="38a31201-f909-4a45-9792-a5d72225f060" src="https://cdn.javarush.com/images/article/38a31201-f909-4a45-9792-a5d72225f060/original.png" alt="">
<p>Модель даних Hbase можна запам'ятати, як відповідність ключ значення: </p>

<pre><code>&lt;table, RowKey, Column Family, Column, timestamp> -> Value
</code></pre>
<h2>6.3 Підтримувані операції </h2>
<p>Список підтримуваних операцій у hbase дуже простий. Підтримуються 4 основні операції: </p>
<ul>
    <li><strong>Put</strong>: додати новий запис до hbase. Timestamp цього запису може бути заданий руками, інакше він
        буде встановлений автоматично як поточний час.</li>
    <li><strong>Get</strong>: отримати дані щодо певного RowKey. Можна вказати Column Family, з якої будемо брати дані та кількість версій, які хочемо прочитати.</li>
    <li><strong>Scan</strong>: читати записи по черзі. Можна вказати запис з яким починаємо читати, запис до якого читати, кількість записів, які необхідно вважати, Column Family з якої буде проводитися читання та максимальна кількість версій для кожного запису. </li>
    <li><strong>Delete</strong>: позначити певну версію для видалення. Фізичного видалення при цьому не відбудеться, воно буде відкладено до наступного Major Compaction (див. нижче). </li>
</ul>
<h2>4. Архітектура </h2>
<p>HBase є розподіленою базою даних, яка може працювати на десятках і сотнях фізичних серверів, забезпечуючи безперебійну роботу навіть у разі виходу з ладу деяких з них. Тому архітектура HBase досить складна в порівнянні з класичними реляційними базами даних. </p>
<img data-max-width="1024" data-id="5bae086c-b213-47db-be33-a23d854a1543" src="https://cdn.javarush.com/images/article/5bae086c-b213-47db-be33-a23d854a1543/original.png" alt="">
<p>HBase для своєї роботи використовує два основні процеси: </p>
<p><strong>1. Region Server</strong> — обслуговує один або кілька регіонів. Регіон — це діапазон записів, що відповідають певному діапазону RowKey, що йдуть поспіль. Кожен регіон містить: </p>
<ul>
    <li><strong>Persistent Storage</strong> — основне сховище даних у HBase. Дані фізично зберігаються на HDFS у спеціальному форматі HFile. Дані HFile зберігаються в відсортованому за RowKey порядку. Одній парі (регіон, column family) відповідає щонайменше один HFIle. </li>
    <li><strong>MemStore</strong> — буфер для запису. Так як дані зберігаються в HFile у відсортованому порядку — оновлювати HFile на кожен запис досить дорого. Натомість дані під час запису потрапляють у спеціальну область пам'яті MemStore, де накопичуються деякий час. У разі заповнення MemStore до певного критичного значення дані записуються до нового HFile. </li>
    <li><strong>BlockCache</strong> — кеш для читання. Дозволяє суттєво економити час на даних, які читаються часто. </li>
    <li><strong>Write Ahead Log (WAL)</strong>. Оскільки дані під час запису потрапляють у memstore, існує певний ризик втрати даних через збій. Для того щоб цього не відбулося, всі операції перед здійсненням маніпуляцій потрапляють до спеціального лог-файлу. Це дозволяє відновити дані після будь-якого збою. </li>
</ul>
<p><strong>2. Master Server</strong> — головний сервер у кластері HBase. Master керує розподілом регіонів за Region Server-ами, веде реєстр регіонів, керує запусками регулярних завдань та робить іншу корисну роботу. </p>
<p>Для координації дій між сервісами HBase використовує Apache ZooKeeper, спеціальний сервіс, призначений для керування конфігураціями та синхронізацією сервісів. </p>
<p>Під час збільшення кількості даних у регіоні та досягненні ним певного розміру Hbase запускає split: операцію, що розбиває регіон на 2. Щоб уникнути постійних поділів регіонів, можна заздалегідь вказати межі регіонів і збільшити їх максимальний розмір. </p>
<p>Оскільки дані по одному регіону можуть зберігатися в декількох HFile, для прискорення роботи Hbase періодично їх зливає воєдино. Ця операція в Hbase називається compaction. Compaction-и бувають двох видів: </p>
<ul>
    <li><strong>Minor Compaction</strong>. Запускається автоматично, виконується у фоновому режимі. Має низький
        пріоритет у порівнянні з іншими операціями Hbase. </li>
    <li><strong>Major Compaction</strong>. Запускається руками або після спрацювання певних тригерів (наприклад за таймером). Має високий пріоритет та може суттєво уповільнити роботу кластера. Major Compaction-и краще робити під час коли навантаження на кластер невелике. Під час Major Compaction також відбувається фізичне видалення даних, рано значених міткою tombstone. </li>
</ul>
<h2>5. Способи роботи з HBase </h2>
<h4>HBase Shell </h4>
<p>Найпростіший спосіб розпочати роботу з Hbase — скористатися утилітою hbase shell. Вона доступна відразу після встановлення hbase на будь-якій ноді кластера hbase.
    <img data-max-width="512" data-id="e1bc7480-e6e9-4358-9632-9349e4bd5a02" src="https://cdn.javarush.com/images/article/e1bc7480-e6e9-33 -9349e4bd5a02/original.png" alt="">
<p>Hbase shell являє собою jruby-консоль із вбудованою підтримкою всіх основних операцій для роботи з Hbase. Нижче наведено приклад створення таблиці users з двома column family, виконання деяких маніпуляцій з нею та видалення таблиці в кінці на мові hbase shell: </p>

<pre><code>create 'users', {NAME => 'user_profile', VERSIONS => 5}, {NAME => 'user_posts', VERSIONS => 1231231231}
put 'users', 'id1', 'user_profile:name', 'olexandr'
put 'users', 'id1', 'user_profile:second_name', 'olexandr'
get 'users', 'id1'
put 'users', 'id1', 'user_profile:second_name', 'kuznietsov'
get 'users', 'id1'
get 'users', 'id1', {COLUMN => 'user_profile:second_name', VERSIONS => 5}
put 'users', 'id2', 'user_profile:name', 'vasyl'
put 'users', 'id2', 'user_profile:second_name', 'ivanov'
scan 'users', {COLUMN => 'user_profile:second_name', VERSIONS => 5}
delete 'users', 'id1', 'user_profile:second_name'
get 'users', 'id1'
disable 'users'
drop 'users'
</code></pre>

<h4>Native API </h4>
<p>Як і більшість інших hadoop-related проєктів, hbase реалізований мовою Java, тому і нативний api доступний мовою Java. Native API досить непогано документований на офіційному сайті. Ось приклад використання Hbase API взятий звідти: </p>

<pre class='language-java line-numbers'><code>
import java.io.IOException;

import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

public class MyLittleHBaseClient {
  public static void main(String[] args) throws IOException {
	Configuration config = HBaseConfiguration.create();
	Connection connection = ConnectionFactory.createConnection(config);
	try {
  	Table table = connection.getTable(TableName.valueOf("myLittleHBaseTable"));
  	try {
    	Put p = new Put(Bytes.toBytes("myLittleRow"));
    	p.add(Bytes.toBytes("myLittleFamily"), Bytes.toBytes("someQualifier"),
    	Bytes.toBytes("Some Value"));
    	table.put(p);

    	Get g = new Get(Bytes.toBytes("myLittleRow"));
    	Result r = table.get(g);
    	byte [] value = r.getValue(Bytes.toBytes("myLittleFamily"),
      	Bytes.toBytes("someQualifier"));

    	String valueStr = Bytes.toString(value);
    	System.out.println("GET: " + valueStr);

    	Scan s = new Scan();
    	s.addColumn(Bytes.toBytes("myLittleFamily"), Bytes.toBytes("someQualifier"));
    	ResultScanner scanner = table.getScanner(s);
    	try {
       	for (Result rr = scanner.next(); rr != null; rr = scanner.next()) {
         	System.out.println("Found row: " + rr);
       	}
     	} finally {
       	scanner.close();
     	}
   	} finally {
     	if (table != null) table.close();
   	}
 	} finally {
   	connection.close();
 	}
  }
}
</code></pre>

<h4>Thrift, REST та підтримка інших мов програмування</h4>
<p>Для роботи з іншими мов програмування Hbase надає Thrift API та Rest API. На їх основі побудовані клієнти для всіх основних мов програмування: python, PHP, Java Script тощо. </p>

<h2>6. Деякі особливості роботи з HBase </h2>

<ol>
    <li><p>Hbase «з коробки» інтегрується з MapReduce, і може бути використана як вхідні та вихідні дані за допомогою спеціальних TableInputFormat і TableOutputFormat. </p></li>
<li><p>Дуже важливо правильно обрати RowKey. RowKey повинен забезпечувати хороший рівномірний розподіл за регіонами, бо в іншому випадку є ризик виникнення так званих «гарячих регіонів» — регіонів, які використовуються набагато частіше за інші, що призводить до неефективного використання ресурсів системи. </p></li>
<li><p>Якщо дані заливаються не поодиноко, а одразу великими пачками, Hbase підтримує спеціальний механізм BulkLoad, який дозволяє заливати дані набагато швидше, ніж використовуючи поодинокі Put-и. BulkLoad по суті є двокроковою операцією: </p>
    <ul>
        <li>Формування HFile без участі put-ів за допомогою спеціального MapReduce job-и</li>
        <li>Підкладання цих файликів безпосередньо в Hbase</li>
    </ul>
</li>
<li><p>Hbase підтримує виведення своїх метрик до сервера моніторингу Ganglia. Це може бути дуже корисно під час адміністрування Hbase для розуміння суті проблем, що відбуваються з hbase. </p></li>
</ol>
<h4>RowKey </h4>
<p>В якості RowKey використовується ідентифікатор користувача, в якості якого використовується GUUID, рядок, що спеціально генерується таким чином, щоб бути унікальним у всьому світі. GUUID-и розподілені рівномірно, що дає добрий розподіл даних по серверам. </p>
<h4>Column Family </h4>
<p>У нашому сховищі використовуються дві column family: </p>
<ul>
    <li>Data. У цій групі колонок зберігаються дані, які втрачають актуальність для рекламних цілей, такі як факти відвідування користувачем певних URL. TTL на цю Column Family встановлено у розмірі 2 місяці, обмеження за кількістю версій — 2000. </li>
    <li>LongData. У цій групі колонок зберігаються дані, які не втрачають своєї актуальності протягом тривалого часу, такі як стать, дата народження та інші «вічні» характеристики користувача. </li>
</ul> <h4>Колонки </h4>
<p> Кожен тип фактів про користувача зберігається в окремій колонці. Наприклад, у колонці Data:_v зберігаються URL, відвідані користувачем, а в колонці LongData:gender — стать користувача. </p>
<p>Як timestamp зберігається час реєстрації цього факту. Наприклад, у колонці Data:_v як timestamp використовується час заходу користувачем певний URL. </p>
<p>Така структура зберігання даних дуже добре лягає на наш патерн використання і дозволяє швидко оновлювати дані про користувачів, швидко діставати всю необхідну інформацію про користувачів, і, використовуючи MapReduce, швидко обробляти дані про всіх користувачів одразу. </p>
<h2>7. Альтернативи </h2>
<p>HBase досить складна в адмініструванні та використанні, тому перш ніж використовувати HBase є сенс звернути увагу на альтернативи: </p>
<ul>
    <li><p><strong>Реляційні бази даних</strong>. Дуже непогана альтернатива, особливо якщо дані влазять на одну машину. Також насамперед про реляційні бази даних варто подумати у разі, коли важливі транзакції індекси, що відрізняються від первинного. </p></li>
    <li><p><strong>Key-Value сховища</strong>. Такі сховища, як Redis і Aerospike краще підходять, коли необхідна мінімізація latency і менш важлива пакетна обробка даних. </p></li>
    <li><p><strong>Файли та їх обробка за допомогою MapReduce</strong>. Якщо дані лише додаються, і рідко оновлюються/змінюються, краще не використовувати HBase, а просто зберігати дані у файлах. Для спрощення роботи з файлами можна скористатися такими інструментами як Hive, Pig і Impala. </p></li>
</ul>

<p>Використання HBase виправдане, коли: </p>

<ul>
    <li>Даних багато, і вони не влізають на один комп'ютер/сервер </li>
    <li>Данні часто оновлюються та видаляються </li>
    <li>У даних присутній явний «ключ» за яким зручно прив'язувати все інше </li>
    <li>Потрібна пакетна обробка даних </li>
    <li>Потрібен довільний доступ до даних за певним ключем</li>
</ul>